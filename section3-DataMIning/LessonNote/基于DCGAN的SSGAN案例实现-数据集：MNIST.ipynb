{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7445e13c-fd9a-4273-96e8-ca2798f9e3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必备依赖\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 导入图像数据增广对象\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 导入图像保存对象\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "# 导入数据集加载对象\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 导入torch自带数据集，稍后从中下载并使用MNIST数据集\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d43c861e-54e3-4abc-81cb-63de9634067b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建保存生成图像的文件夹\n",
    "os.makedirs(\"./images\", exist_ok=True)\n",
    "\n",
    "epoches = 50 # 总训练轮数；考虑到没必要面向生产，仅作为算法学习使用的简单demo，出于节约成本的考量，训练轮数仅设计为50轮即可\n",
    "batch_size = 64 # 一个训练step输入的sample数量\n",
    "init_lr = 0.0002 # Adam优化器初始化学习率\n",
    "b1 = 0.5 # Adam优化器的第一个动量衰减参数\n",
    "b2 = 0.999 # Adam优化器的第二个动量衰减参数\n",
    "n_cpu = 8 # 用于一次生成的CPU线程数\n",
    "latent_dim = 100 # 候选空间的维度\n",
    "num_classes = 10 # sample的label的类别总数\n",
    "img_size = 32 # 单个输入图像的尺寸 - 宽高相等\n",
    "channels = 1 # 输入图像的通道数 - 灰度图，单通道即可\n",
    "sample_interval = 400 # 图像采样间隔\n",
    "\n",
    "# 如果 GPU 可用，则使用 CUDA 加速\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1061c027-e40c-4070-a9c4-23f7131997f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化模型权重\n",
    "def weights_init_normal(m):\n",
    "    '''\n",
    "    传入model，初始化model的权重\n",
    "    '''\n",
    "    \n",
    "    # 通过传入的model获取其类名\n",
    "    classname = m.__class__.__name__\n",
    "    \n",
    "    # 如果是卷积网络\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    \n",
    "    # 否则就不是\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0062db4c-72cd-42c4-9fd5-9e5d51191e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义生成器对象 - 这里就是DCGAN的Generator\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        # 创建一个标签嵌入层，用于将条件标签映射到潜在空间\n",
    "        self.label_emb = nn.Embedding(num_classes, latent_dim)\n",
    "\n",
    "        # 初始化图像尺寸，用于上采样之前\n",
    "        self.init_size = img_size // 4  # Initial size before upsampling\n",
    "\n",
    "        # 第一个全连接层，将随机噪声映射到合适的维度\n",
    "        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        # 生成器的卷积块\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            \n",
    "            # BN纵向规范\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        out = self.l1(noise)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            \"\"\"返回每个鉴别器块的层\"\"\"\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        # 鉴别器的卷积块\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            *discriminator_block(channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        # 下采样图像的高度和宽度\n",
    "        ds_size = img_size // 2 ** 4\n",
    "\n",
    "        # 输出层\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())  # 用于鉴别真假的输出层\n",
    "        self.aux_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, num_classes + 1), nn.Softmax())  # 用于鉴别类别的输出层\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.conv_blocks(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "        label = self.aux_layer(out)\n",
    "\n",
    "        return validity, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42023afa-e592-45a2-bf75-51c8186e3962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "adversarial_loss = torch.nn.BCELoss()  # 二元交叉熵损失，用于对抗训练\n",
    "auxiliary_loss = torch.nn.CrossEntropyLoss()  # 交叉熵损失，用于辅助分类\n",
    "\n",
    "# 初始化生成器和鉴别器\n",
    "generator = Generator()  # 创建生成器实例\n",
    "discriminator = Discriminator()  # 创建鉴别器实例\n",
    "\n",
    "# 如果使用GPU，将模型和损失函数移至GPU上\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    adversarial_loss.cuda()\n",
    "    auxiliary_loss.cuda()\n",
    "\n",
    "# 初始化模型权重\n",
    "generator.apply(weights_init_normal)  # 初始化生成器的权重\n",
    "discriminator.apply(weights_init_normal)  # 初始化鉴别器的权重\n",
    "\n",
    "# 配置数据加载器\n",
    "os.makedirs(\"./data/mnist\", exist_ok=True)  # 创建存储MNIST数据集的文件夹\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        \"./data/mnist\",\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
    "        ),\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# 优化器\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=init_lr, betas=(b1, b2))  # 生成器的优化器\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=init_lr, betas=(b1, b2))  # 鉴别器的优化器\n",
    "\n",
    "# 根据是否使用GPU选择数据类型\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88648dfa-8dda-48ce-9255-0b2f456f17e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ma-user/anaconda3/envs/PyTorch-2.0.0/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/50] [Batch 937/938] [D loss: 1.368545, acc: 50%] [G loss: 0.704623]\n",
      "[Epoch 1/50] [Batch 937/938] [D loss: 1.387643, acc: 50%] [G loss: 0.786353]\n",
      "[Epoch 2/50] [Batch 937/938] [D loss: 1.369781, acc: 50%] [G loss: 0.674227]\n",
      "[Epoch 3/50] [Batch 937/938] [D loss: 1.345224, acc: 51%] [G loss: 0.772573]\n",
      "[Epoch 4/50] [Batch 937/938] [D loss: 1.339223, acc: 51%] [G loss: 0.747099]\n",
      "[Epoch 5/50] [Batch 937/938] [D loss: 1.287006, acc: 51%] [G loss: 0.851946]\n",
      "[Epoch 6/50] [Batch 937/938] [D loss: 1.357881, acc: 53%] [G loss: 1.010694]\n",
      "[Epoch 7/50] [Batch 937/938] [D loss: 1.415346, acc: 45%] [G loss: 0.834191]\n",
      "[Epoch 8/50] [Batch 937/938] [D loss: 1.344990, acc: 53%] [G loss: 0.821848]\n",
      "[Epoch 9/50] [Batch 937/938] [D loss: 1.357066, acc: 57%] [G loss: 0.760246]\n",
      "[Epoch 10/50] [Batch 937/938] [D loss: 1.218984, acc: 50%] [G loss: 0.914214]\n",
      "[Epoch 11/50] [Batch 937/938] [D loss: 1.251535, acc: 50%] [G loss: 1.077527]\n",
      "[Epoch 12/50] [Batch 937/938] [D loss: 1.388343, acc: 53%] [G loss: 0.718448]\n",
      "[Epoch 13/50] [Batch 937/938] [D loss: 1.353298, acc: 53%] [G loss: 0.731445]\n",
      "[Epoch 14/50] [Batch 937/938] [D loss: 1.359731, acc: 56%] [G loss: 1.184589]\n",
      "[Epoch 15/50] [Batch 937/938] [D loss: 1.314991, acc: 51%] [G loss: 0.576275]\n",
      "[Epoch 16/50] [Batch 937/938] [D loss: 1.296063, acc: 51%] [G loss: 0.791716]\n",
      "[Epoch 17/50] [Batch 937/938] [D loss: 1.400085, acc: 50%] [G loss: 0.924966]\n",
      "[Epoch 18/50] [Batch 937/938] [D loss: 1.208153, acc: 62%] [G loss: 0.850141]\n",
      "[Epoch 19/50] [Batch 937/938] [D loss: 1.173312, acc: 54%] [G loss: 1.282142]\n",
      "[Epoch 20/50] [Batch 937/938] [D loss: 1.353307, acc: 50%] [G loss: 0.951352]\n",
      "[Epoch 21/50] [Batch 937/938] [D loss: 1.553891, acc: 43%] [G loss: 0.921823]\n",
      "[Epoch 22/50] [Batch 937/938] [D loss: 1.222543, acc: 57%] [G loss: 0.923216]\n",
      "[Epoch 23/50] [Batch 937/938] [D loss: 1.240449, acc: 64%] [G loss: 0.604797]\n",
      "[Epoch 24/50] [Batch 937/938] [D loss: 1.141712, acc: 59%] [G loss: 1.067746]\n",
      "[Epoch 25/50] [Batch 937/938] [D loss: 1.351497, acc: 45%] [G loss: 1.668935]\n",
      "[Epoch 26/50] [Batch 937/938] [D loss: 1.268784, acc: 59%] [G loss: 0.580247]\n",
      "[Epoch 27/50] [Batch 937/938] [D loss: 1.354771, acc: 57%] [G loss: 0.796699]\n",
      "[Epoch 28/50] [Batch 937/938] [D loss: 1.126998, acc: 62%] [G loss: 1.141732]\n",
      "[Epoch 29/50] [Batch 937/938] [D loss: 1.381321, acc: 48%] [G loss: 0.495940]\n",
      "[Epoch 30/50] [Batch 937/938] [D loss: 1.158088, acc: 54%] [G loss: 0.748143]\n",
      "[Epoch 31/50] [Batch 937/938] [D loss: 1.193817, acc: 60%] [G loss: 1.646887]\n",
      "[Epoch 32/50] [Batch 937/938] [D loss: 1.482077, acc: 48%] [G loss: 1.041353]\n",
      "[Epoch 33/50] [Batch 937/938] [D loss: 1.221154, acc: 59%] [G loss: 1.256497]\n",
      "[Epoch 34/50] [Batch 937/938] [D loss: 1.208503, acc: 64%] [G loss: 1.847292]\n",
      "[Epoch 35/50] [Batch 937/938] [D loss: 1.132568, acc: 64%] [G loss: 2.033698]\n",
      "[Epoch 36/50] [Batch 937/938] [D loss: 1.169540, acc: 59%] [G loss: 2.222381]\n",
      "[Epoch 37/50] [Batch 937/938] [D loss: 1.373616, acc: 50%] [G loss: 0.976109]\n",
      "[Epoch 38/50] [Batch 937/938] [D loss: 1.413775, acc: 48%] [G loss: 0.717697]\n",
      "[Epoch 39/50] [Batch 937/938] [D loss: 1.291254, acc: 53%] [G loss: 0.435826]\n",
      "[Epoch 40/50] [Batch 937/938] [D loss: 1.144060, acc: 60%] [G loss: 0.511594]\n",
      "[Epoch 41/50] [Batch 937/938] [D loss: 1.269584, acc: 53%] [G loss: 1.158676]\n",
      "[Epoch 42/50] [Batch 937/938] [D loss: 1.149203, acc: 64%] [G loss: 2.471077]\n",
      "[Epoch 43/50] [Batch 937/938] [D loss: 1.441737, acc: 50%] [G loss: 0.307894]\n",
      "[Epoch 44/50] [Batch 937/938] [D loss: 1.152933, acc: 59%] [G loss: 1.329355]\n",
      "[Epoch 45/50] [Batch 937/938] [D loss: 1.016832, acc: 76%] [G loss: 0.503921]\n",
      "[Epoch 46/50] [Batch 937/938] [D loss: 1.240385, acc: 59%] [G loss: 0.907747]\n",
      "[Epoch 47/50] [Batch 937/938] [D loss: 1.116813, acc: 57%] [G loss: 0.479591]\n",
      "[Epoch 48/50] [Batch 937/938] [D loss: 1.164548, acc: 67%] [G loss: 3.151580]\n",
      "[Epoch 49/50] [Batch 937/938] [D loss: 1.011089, acc: 67%] [G loss: 1.922915]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoches):\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "\n",
    "        batch_size = imgs.shape[0]\n",
    "\n",
    "        # 定义对抗训练的标签\n",
    "        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)  # 用于真实样本\n",
    "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)  # 用于生成样本\n",
    "        fake_aux_gt = Variable(LongTensor(batch_size).fill_(num_classes), requires_grad=False)  # 用于生成样本的类别标签\n",
    "\n",
    "        # 配置输入数据\n",
    "        real_imgs = Variable(imgs.type(FloatTensor))  # 真实图像\n",
    "        labels = Variable(labels.type(LongTensor))  # 真实类别标签\n",
    "\n",
    "        # -----------------\n",
    "        #  训练生成器\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # 采样噪声和类别标签作为生成器的输入\n",
    "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, latent_dim))))\n",
    "\n",
    "        # 生成一批图像\n",
    "        gen_imgs = generator(z)\n",
    "\n",
    "        # 计算生成器的损失，衡量生成器欺骗鉴别器的能力\n",
    "        validity, _ = discriminator(gen_imgs)\n",
    "        g_loss = adversarial_loss(validity, valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  训练鉴别器\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # 真实图像的损失\n",
    "        real_pred, real_aux = discriminator(real_imgs)\n",
    "        d_real_loss = (adversarial_loss(real_pred, valid) + auxiliary_loss(real_aux, labels)) / 2\n",
    "\n",
    "        # 生成图像的损失\n",
    "        fake_pred, fake_aux = discriminator(gen_imgs.detach())\n",
    "        d_fake_loss = (adversarial_loss(fake_pred, fake) + auxiliary_loss(fake_aux, fake_aux_gt)) / 2\n",
    "\n",
    "        # 总的鉴别器损失\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        # 计算鉴别器准确率\n",
    "        pred = np.concatenate([real_aux.data.cpu().numpy(), fake_aux.data.cpu().numpy()], axis=0)\n",
    "        gt = np.concatenate([labels.data.cpu().numpy(), fake_aux_gt.data.cpu().numpy()], axis=0)\n",
    "        d_acc = np.mean(np.argmax(pred, axis=1) == gt)\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % sample_interval == 0:\n",
    "            save_image(gen_imgs.data[:25], \"./images/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "\n",
    "    print(\n",
    "        \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f, acc: %d%%] [G loss: %f]\"\n",
    "        % (epoch, epoches, i, len(dataloader), d_loss.item(), 100 * d_acc, g_loss.item())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543a6faa-97cf-4a45-b019-257f2c5d78fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch-2.0.0",
   "language": "python",
   "name": "pytorch-2.0.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
